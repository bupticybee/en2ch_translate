{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the preprocressed corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('middleresult/tokenlizer_output_100000ch_120000en_35words.pkl','rb') as fhdl:\n",
    "    (\n",
    "         ind2ch,\n",
    "         ch2ind,\n",
    "         ind2en,\n",
    "         en2ind,\n",
    "         train_x,\n",
    "         train_y,\n",
    "    ) = pickle.load(fhdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 120000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind2ch),len(ind2en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the model hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_vocab_size = 50003#len(ind2en) + 3\n",
    "target_vocat_size = 50003#len(ind2ch) + 3\n",
    "attention_hidden_size = 1024\n",
    "attention_output_size = 1024\n",
    "embedding_size = 1024\n",
    "seq_max_len = 40\n",
    "num_units = 1024\n",
    "batch_size = 64\n",
    "layer_number = 4\n",
    "max_grad = 1.0\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797140, 1797140)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x),len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = tf.contrib.keras.preprocessing.sequence.pad_sequences(train_x,seq_max_len,padding='post')\n",
    "train_y = tf.contrib.keras.preprocessing.sequence.pad_sequences(train_y,seq_max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hunter watched for the hare to come out of the burrow .                           \n",
      "猎人 守候 着 兔子 从 洞里 出来 。                                \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0,len(train_x))\n",
    "print(' '.join([ind2en.get(i,'') for i in train_x[index]]))\n",
    "print(' '.join([ind2ch.get(i,'') for i in train_y[index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797140, 40), (1797140, 40))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(train_x,train_y , test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x[train_x >= src_vocab_size] = 1 \n",
    "test_x[test_x >= src_vocab_size] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y[train_y >= target_vocat_size] = 1 \n",
    "test_y[test_y >= target_vocat_size] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_last_index = src_vocab_size - 1\n",
    "y_last_index = src_vocab_size - 1\n",
    "\n",
    "ind2en[x_last_index] = '<go>'\n",
    "ind2ch[y_last_index] = '<go>'\n",
    "en2ind['<go>'] = x_last_index\n",
    "ch2ind['<go>'] = y_last_index\n",
    "\n",
    "ind2en[1] = '<unk>'\n",
    "ind2ch[1] = '<unk>'\n",
    "en2ind['<unk>'] = 1\n",
    "ch2ind['<unk>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "being a modest person , he was content to play second fiddle to others .                         \n",
      "作为 一个 谦虚 者 ， 他 愿意 居于 他人 的 次要 位置 。                           \n",
      "and dad says , \" <unk> , give <unk> more space around the dinner table . \"                       \n",
      "我爸 说 ， <unk> ， 让 点 位子 给 盖尔                              \n",
      "and tonight is our night , so relax .                               \n",
      "今晚 是 我们 的 时刻 ， 放松 吧 ！                               \n",
      "the key to solving the problems we are now facing                              \n",
      "解决 我们 面临 问题 的 关键                                  \n",
      "the book says cut the red wire .                                \n",
      "书上 说 要 剪 红线                                   \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(5):\n",
    "    index = random.randint(0,len(train_x))\n",
    "    print(' '.join([ind2en.get(i,'') for i in train_x[index]]))\n",
    "    print(' '.join([ind2ch.get(i,'') for i in train_y[index]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the translate nmt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True,allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    initializer = tf.random_uniform_initializer(\n",
    "        -0.08, 0.08)\n",
    "    tf.get_variable_scope().set_initializer(initializer)\n",
    "    \n",
    "    x = tf.placeholder(\"int32\", [None, None])\n",
    "    y = tf.placeholder(\"int32\", [None, None])\n",
    "    y_in = tf.placeholder(\"int32\",[None,None])\n",
    "    x_len = tf.placeholder(\"int32\",[None])\n",
    "    y_len = tf.placeholder(\"int32\",[None])\n",
    "    x_real_len = tf.placeholder(\"int32\",[None])\n",
    "    y_real_len = tf.placeholder(\"int32\",[None])\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "    # embedding\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", [src_vocab_size, embedding_size],dtype=tf.float32)\n",
    "    embedding_decoder = tf.get_variable(\n",
    "        \"embedding_decoder\", [target_vocat_size, embedding_size],dtype=tf.float32)\n",
    "    \n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, x)\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_decoder, y_in)\n",
    "    \n",
    "    # encoder\n",
    "    num_bi_layers = int(layer_number / 2)\n",
    "    cell_list = []\n",
    "    for i in range(num_bi_layers):\n",
    "        cell_list.append(\n",
    "            tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(num_units), input_keep_prob=(1.0 - dropout)\n",
    "            )\n",
    "        )\n",
    "    if len(cell_list) == 1:\n",
    "        encoder_cell = cell_list[0]\n",
    "    else:\n",
    "        encoder_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "        \n",
    "    cell_list = []\n",
    "    \n",
    "    for i in range(num_bi_layers):\n",
    "        cell_list.append(\n",
    "            tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(num_units), input_keep_prob=(1.0 - dropout)\n",
    "            )\n",
    "        )\n",
    "    if len(cell_list) == 1:\n",
    "        encoder_backword_cell = cell_list[0]\n",
    "    else:\n",
    "        encoder_backword_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "    \n",
    "    bi_outputs, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        encoder_cell,encoder_backword_cell, encoder_emb_inp,\n",
    "        sequence_length=x_len,dtype=tf.float32)\n",
    "    encoder_outputs = tf.concat(bi_outputs, -1)\n",
    "    \n",
    "    if num_bi_layers == 1:\n",
    "        encoder_state = bi_encoder_state\n",
    "    else:\n",
    "        encoder_state = []\n",
    "        for layer_id in range(num_bi_layers):\n",
    "            encoder_state.append(bi_encoder_state[0][layer_id])  # forward\n",
    "            encoder_state.append(bi_encoder_state[1][layer_id])  # backward\n",
    "        encoder_state = tuple(encoder_state)\n",
    "    \n",
    "    # decoder \n",
    "    #decoder_cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "    cell_list = []\n",
    "    for i in range(layer_number):\n",
    "        cell_list.append(\n",
    "            tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(num_units), input_keep_prob=(1.0 - dropout)\n",
    "            )\n",
    "        )\n",
    "    if len(cell_list) == 1:\n",
    "        decoder_cell = cell_list[0]\n",
    "    else:\n",
    "        decoder_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "    \n",
    "    # Helper\n",
    "    \n",
    "    # attention\n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "        attention_hidden_size, encoder_outputs,\n",
    "        memory_sequence_length=x_real_len,scale=True)\n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "        decoder_cell, attention_mechanism,\n",
    "        attention_layer_size=attention_output_size)\n",
    "    \n",
    "    \n",
    "    projection_layer = layers_core.Dense(\n",
    "        target_vocat_size, use_bias=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dynamic decoding\n",
    "    with tf.variable_scope(\"decode_layer\"):\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            decoder_emb_inp,sequence_length= y_len)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, initial_state = decoder_cell.zero_state(dtype=tf.float32,batch_size=batch_size),\n",
    "            output_layer=projection_layer)\n",
    "       \n",
    "        outputs, _,___  = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "        logits = outputs.rnn_output\n",
    "\n",
    "        target_weights = tf.sequence_mask(\n",
    "            y_real_len, seq_max_len, dtype=logits.dtype)\n",
    "    \n",
    "    # predicting\n",
    "    # Helper\n",
    "    with tf.variable_scope(\"decode_layer\", reuse=True):\n",
    "        helper_predict = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding_decoder,\n",
    "            tf.fill([batch_size], ch2ind['<go>']), 0)\n",
    "        decoder_predict = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper_predict, initial_state = decoder_cell.zero_state(dtype=tf.float32,batch_size=batch_size),\n",
    "            output_layer=projection_layer)\n",
    "        outputs_predict,_, __ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder_predict, maximum_iterations=test_y.shape[1] * 2)\n",
    "    translations = outputs_predict.sample_id\n",
    "\n",
    "    # calculate loss\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=logits)\n",
    "    train_loss = (tf.reduce_sum(crossent * target_weights) /\n",
    "        batch_size)\n",
    "    \n",
    "    optimizer_ori = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, trainable_params)\n",
    "    clip_gradients, _ = tf.clip_by_global_norm(gradients, max_grad)\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = optimizer_ori.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params), global_step=global_step)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(train_loss)\n",
    "    #trainop = tflearn.TrainOp(loss=train_loss, optimizer=optimizer,\n",
    "    #                          metric=train_loss, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_acc(logits,target):\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target[:,:seq_max_len], logits[:,:seq_max_len]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from middleresult/align_word_deep/result_2_27796\n"
     ]
    }
   ],
   "source": [
    "saver.restore(session,'middleresult/align_word_deep/result_2_27796')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'middleresult/result_word_deep'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(session,'middleresult/result_word_deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import Dataset,ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "train_set = Dataset(train_x,train_y)\n",
    "test_set = Dataset(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bleu_score(predict,target):\n",
    "    try:\n",
    "        target = [[[j for index,j in enumerate(i) if j > 0 or index < 4]] for i in target]\n",
    "        predict = [[j for index,j in enumerate(i) if j > 0 or index < 4] for i in predict]\n",
    "        BLEUscore = nltk.translate.bleu_score.corpus_bleu(target,predict)\n",
    "    except:\n",
    "        BLEUscore = -1\n",
    "    return BLEUscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_test_loss(test_set = Dataset(test_x,test_y),display=True):\n",
    "    accs = []\n",
    "    worksum = int(len(test_x) / batch_size)\n",
    "    loss_list = []\n",
    "    predict_list = []\n",
    "    target_list = []\n",
    "    source_list = []\n",
    "    pb = ProgressBar(worksum=worksum,info=\"validating...\",auto_display=display)\n",
    "    pb.startjob()\n",
    "    #test_set = Dataset(test_x,test_y)\n",
    "    for j in range(worksum):\n",
    "        batch_x,batch_y = test_set.next_batch(batch_size)\n",
    "        lx = [seq_max_len] * batch_size\n",
    "        ly = [seq_max_len] * batch_size\n",
    "        bx = [np.sum(m > 0) for m in batch_x]\n",
    "        by = [np.sum(m > 0) for m in batch_y]\n",
    "        tmp_loss,tran = session.run([train_loss,translations],feed_dict={x:batch_x,y:batch_y,\n",
    "                                                     y_in:\n",
    "                                                     np.concatenate((\n",
    "                                                     np.ones((batch_y.shape[0],1),dtype=np.int) * ch2ind['<go>'],batch_y[:,:-1]) ,axis=1)\n",
    "                                                     ,x_len:lx,y_len:ly,\n",
    "                                                                        y_real_len:by,\n",
    "                                                                        x_real_len:bx})\n",
    "        loss_list.append(tmp_loss)\n",
    "        tmp_acc = cal_acc(tran,batch_y)\n",
    "        accs.append(tmp_acc)\n",
    "        predict_list += [i for i in tran]\n",
    "        target_list += [i for i in batch_y]\n",
    "        source_list += [i for i in batch_x]\n",
    "        pb.complete(1)\n",
    "    return np.average(loss_list),np.average(accs),get_bleu_score(predict_list,target_list),predict_list,target_list,source_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the initial loss and see what model outputs in the begining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating... 100.00 % [==================================================>] 280/280 \t used:322s eta:0 s"
     ]
    }
   ],
   "source": [
    "w_loss,w_acc,bleu_score,predict_list,target_list,source_list = calc_test_loss(Dataset(train_x[::100],train_y[::100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.89665, 5.5803571428571429e-06, 0.09401507732715986)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_loss,w_acc,bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_text(x):\n",
    "    return [' '.join([ind2ch.get(j,'') for j in i]) for i in x]\n",
    "def get_all_en_text(x):\n",
    "    return [' '.join([ind2en.get(j,'') for j in i]) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soc soc soc soc soc soc 村 用刀 村 换气 换气 主体 主体 源岩 主体 三类 带个 三类 干涸 特使 毛病 毛病 毛病 一分钟 条码 条码 条码 条码 小牛 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 条码 成团 成团 成团 成团 成团 袜子 袜子 袜子 袜子 变质 成团 变质 变质 变质 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 浇灌 居住者 苹果酸 苹果酸 苹果酸 浇灌 苹果酸 苹果酸 苹果酸 苹果酸 血糖',\n",
       " '里夫 里夫 里夫 里夫 量度 通达 通达 通达 通达 通达 通达 显微镜 显微镜 再要 再要 再要 翻滚 翻滚 翻滚 翻滚 翻滚 翻滚 翻滚 扭伤 吸干 光彩照人 光彩照人 光彩照人 宣告破产 翻倒 翻倒 宣告破产 宣告破产 宣告破产 宣告破产 热电厂 热电厂 凸出 软盘 软盘 ４ ４ 软盘 发达国家 软盘 发达国家 榜 icp 无线 罗素 罗素 罗素 罗素 罗素 罗素 罗素 罗素 罗素 罗素 罗素 罗素 做错事 做错事 做错事 做错事 初期 做错事 初期 初期 做错事 初期 初期 初期 初期 初期 初期 初期 主程序 主程序 主程序',\n",
       " '复合板 复合板 复合板 复合板 复合板 复合板 复合板 复合板 复合板 复合板 复合板 复合板 平和 平和 最深处 最深处 复合板 穿 六点钟 穿 剪刀 穿 穿 穿 穿 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 冻干 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 成团 二维 公共交通 公共交通 公共交通 公共交通 品性 品性 复合板 复合板 复合板 确 复合板 公共交通 确 英亩 英亩 英亩',\n",
       " '分租 分租 分租 厚厚 一定量 令人讨厌 令人讨厌 令人讨厌 令人讨厌 速冻 探讨 探讨 探讨 探讨 探讨 探讨 探讨 探讨 探讨 探讨 分子筛 探讨 探讨 分子筛 分子筛 山区 质地 分子筛 质地 分子筛 源代码 烟火 烟火 烟火 烟火 烟火 烟火 烟火 原虫 圆柱齿轮 原虫 黑暗 黑暗 黑暗 登入 登入 圆珠笔 圆珠笔 圆珠笔 崖 星球大战 虚无 虚无 虚无 虚无 虚无 虚无 虚无 星球大战 虚无 虚无 虚无 发达国家 发达国家 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 水蒸汽 欣赏 水蒸汽 水蒸汽 水蒸汽 甘愿 水蒸汽',\n",
       " 'cd2 cd2 cd2 cd2 cd2 soc 星团 星团 星团 cd2 银行业务 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 cd2 马祖 马祖 马祖 人影 胆总管 胆总管 恋情 恋情 恋情 恋情 恋情 当期 分节 相左 当期 抬起头来 相左 腋窝 罗拉 西德 影像 罗拉 白求恩 几场 白求恩 白求恩 soc soc soc soc soc soc soc soc 发行商 发行商 soc soc soc 村 村 村 村 村 转化率 转化率 毛病 毛病 村 定居者 定居者',\n",
       " '进行曲 进行曲 公交车 公交车 刑期 刑期 轻率地 太阳 轻率地 刑期 轻率地 轻率地 轻率地 轻率地 太低 圈子 mgo 银行业务 分工 面上 面上 银行业务 蓝领 蓝领 赔偿 赔偿 赔偿 赔偿 赔偿 麻省理工 麻省理工 30 为界 为界 为界 为界 为界 为界 麻省理工 麻省理工 麻省理工 琐碎 示威 示威 示威 箱体 箱体 私事 真实感 真实感 会址 会址 会址 浦东 痘苗 kevin 浦东 浦东 飞快 浦东 deh deh deh deh 体制 体制 û û û 安全级别 û 菊酯 反诉 反诉 知悉 氨 氨 氨 氨 望见',\n",
       " '分租 分租 分租 分租 分租 令人讨厌 soc 世贸组织 世贸组织 星团 星团 世贸组织 出去 出去 出去 出去 出去 出去 出去 罗德里格斯 罗德里格斯 罗德里格斯 罗德里格斯 铰链 条码 条码 复合板 复合板 复合板 皮 皮 固 皮 固 固 固 固 固 固 刑期 迭代法 刑期 刑期 刑期 刑期 刑期 蜷缩 b股 刑期 刑期 刑期 第五届 红楼梦 红楼梦 刑期 欣赏 欣赏 欣赏 欣赏 欣赏 欣赏 平地 转管 一首歌 取证 一首歌 通关 通关 通关 当期 通关 通关 项 项 项 项 项 项 项 项',\n",
       " 'marc marc marc marc marc marc 香精 香精 香精 残奥会 残奥会 残奥会 残奥会 udp 残奥会 残奥会 udp 残奥会 udp udp udp udp udp udp udp udp 小规模 小规模 小规模 农村基层 肿大 肿大 肿大 肿大 肿大 肿大 肿大 马鹿 肿大 肿大 肿大 马鹿 马鹿 马鹿 马鹿 马鹿 马鹿 马鹿 马鹿 马鹿 日益严重 原核 原核 原核 原核 原核 原核 原核 原核 原核 原核 原核 腮腺炎 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 社会性 贸易总额 社会性 贸易总额 贸易总额',\n",
       " '取证 取证 取证 取证 取证 取证 取证 取证 取证 取证 取证 取证 取证 取证 组长 组长 组长 组长 组长 组长 取证 取证 取证 取证 bin bin 取证 取证 火灾 bin 挖孔 挖孔 bin 挖孔 取证 取证 取证 取证 映衬 映衬 映衬 面包师 映衬 映衬 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口 流动人口',\n",
       " '瓷砖 瓷砖 瓷砖 万年前 售货员 售货员 javascript javascript javascript javascript cd2 cd2 童年时期 凑合 童年时期 童年时期 凑合 代为 代为 代为 起球 起球 起球 起球 起球 起球 起球 起球 结束 结束 i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ i̇ 刁难 刁难 刁难 喉结 喉结 喉结 喉结 糖原 喉结 喉结 细心 细心 细心 细心 抽水 抽水 阊 喜不喜欢 售货员 颈椎病 颈椎病 作成 抽水 巴勒斯坦国 巴勒斯坦国 作成 rpc 蚁群 蚁群 rpc 测试程序 测试程序 测试程序 测试程序 测试程序 太阳风 测试程序']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = get_all_text(predict_list)\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你 不 去 找 格兰特 博士 吗 ?                                ',\n",
       " '巴德 和 其他 地方 的 成员 正在 意识 到 这 一点 即 你 能否 把 学生 在 从业 前 吸引 过来 ， 你 就 必须 能 把 他们 的 职业 与 科学 挂钩 。      ',\n",
       " '呃 ， <unk> 年 ， 爱迪生 发明 了 断路器 。                              ',\n",
       " '我 保证 付款 将 不 <unk> 六月 末                                ',\n",
       " '<unk> 民族 机床 工业 展示 国际 先进 水平 — — “ <unk> & <unk> 2006 ” 新闻 发布会                      ',\n",
       " '<unk> someone out of something 指 的 是 ‘ 说服 某人 不要 做 某事 / 让 他们 改变 主意 ’ 。                   ',\n",
       " '毕业 后 许多 学生 兴高采烈 。                                  ',\n",
       " '安徽 地区 <unk> 的 研究 与 展望                                 ',\n",
       " '某 一位 舞者 会 超越 当下 ， 超然 出世                               ',\n",
       " '( b ) 该 遗嘱 所作 的 其他 处置 亦须 生效 ， 除非 该 遗嘱 内 显示 出 立遗嘱 人 意欲 该项 处置 因 该段 婚姻 而 撤销 。           ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = get_all_text(target_list)\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tran.shape\n",
    "i_save = 1\n",
    "j_save = 27798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 27798\n"
     ]
    }
   ],
   "source": [
    "print(i_save,j_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'align_word_deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('middleresult/{}'.format(model_path))\n",
    "os.mkdir('eval/{}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating... 100.00 % [==================================================>] 280/280 \t used:265s eta:0 s\n",
      "iter 3 step 6949 train loss 62.169124603271484 train acc 0.6218178013392858 test loss 59.426414489746094 test acc 0.6189327566964287 bleu 0.10504980754240471 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:403s eta:0 s\n",
      "iter 3 step 13898 train loss 57.09894561767578 train acc 0.5874288504464285 test loss 57.24261474609375 test acc 0.5840652901785715 bleu 0.07951183898782706 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:320s eta:0 s\n",
      "iter 3 step 20847 train loss 56.06503677368164 train acc 0.5329617745535714 test loss 56.29206085205078 test acc 0.5302497209821428 bleu 0.053528670373905136 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:260s eta:0 s\n",
      "iter 3 step 27796 train loss 55.227806091308594 train acc 0.6143987165178572 test loss 55.09745407104492 test acc 0.6111788504464286 bleu 0.11660763319373214 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:317s eta:0 s\n",
      "iter 4 step 6949 train loss 52.92161178588867 train acc 0.602914341517857 test loss 54.776458740234375 test acc 0.5990597098214286 bleu 0.09426669394466654 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:293s eta:0 s\n",
      "iter 4 step 13898 train loss 52.5567512512207 train acc 0.6165959821428573 test loss 54.02130126953125 test acc 0.6145047433035714 bleu 0.11731873754961926 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:291s eta:0 s\n",
      "iter 4 step 20847 train loss 52.03689193725586 train acc 0.6215262276785715 test loss 53.67649841308594 test acc 0.6177790178571428 bleu 0.12152755814780629 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:312s eta:0 s\n",
      "iter 4 step 27796 train loss 51.64604568481445 train acc 0.6083523995535713 test loss 52.43077087402344 test acc 0.60548828125 bleu 0.1090827331827403 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:248s eta:0 s\n",
      "iter 5 step 6949 train loss 49.54399108886719 train acc 0.6269893973214286 test loss 52.30046463012695 test acc 0.6208091517857142 bleu 0.12791985900530695 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:312s eta:0 s\n",
      "iter 5 step 13898 train loss 49.442474365234375 train acc 0.6035170200892856 test loss 51.42697525024414 test acc 0.5977232142857143 bleu 0.10425985988996885 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:286s eta:0 s\n",
      "iter 5 step 20847 train loss 49.2879524230957 train acc 0.622509765625 test loss 50.733985900878906 test acc 0.6171595982142857 bleu 0.12797177108547378 lr 1\n",
      "\n",
      "validating... 100.00 % [==================================================>] 280/280 \t used:311s eta:0 s\n",
      "iter 5 step 27796 train loss 49.055049896240234 train acc 0.6185728236607143 test loss 50.58906936645508 test acc 0.6139355468750001 bleu 0.12074278464404048 lr 1\n",
      "\n",
      "iter 6 loss:47.3057975769043 lr:1 18.04 % [=========>-----------------------------------------] 5016/27799 \t used:5340s eta:24253 s"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1024,50003]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop, gradients/decode_layer/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3)]]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1529_gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_59)]]\n\nCaused by op 'gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-6c891c062cb2>\", line 141, in <module>\n    gradients = tf.gradients(train_loss, trainable_params)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 825, in _MatMulGrad\n    grad_b = math_ops.matmul(a, grad, transpose_a=True)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'decode_layer/decoder/while/BasicDecoderStep/dense/MatMul', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-6c891c062cb2>\", line 114, in <module>\n    outputs, _,___  = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\decoder.py\", line 286, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\decoder.py\", line 234, in body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\basic_decoder.py\", line 141, in step\n    cell_outputs = self._output_layer(cell_outputs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 141, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1024,50003]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop, gradients/decode_layer/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3)]]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1529_gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_59)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1024,50003]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop, gradients/decode_layer/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3)]]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1529_gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_59)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5b376073becf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                                 np.ones((batch_y.shape[0],1),dtype=np.int) * ch2ind['<go>'],batch_y[:,:-1]) ,axis=1)\n\u001b[1;32m     28\u001b[0m                                                                 \u001b[1;33m,\u001b[0m\u001b[0my_real_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                                                 \u001b[0mx_real_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                                                                })\n\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1024,50003]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop, gradients/decode_layer/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3)]]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1529_gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_59)]]\n\nCaused by op 'gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-6c891c062cb2>\", line 141, in <module>\n    gradients = tf.gradients(train_loss, trainable_params)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 825, in _MatMulGrad\n    grad_b = math_ops.matmul(a, grad, transpose_a=True)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'decode_layer/decoder/while/BasicDecoderStep/dense/MatMul', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-6c891c062cb2>\", line 114, in <module>\n    outputs, _,___  = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\decoder.py\", line 286, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\decoder.py\", line 234, in body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\basic_decoder.py\", line 141, in step\n    cell_outputs = self._output_layer(cell_outputs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 141, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1024,50003]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/decode_layer/decoder/while/BasicDecoderStep/dense/MatMul_grad/MatMul_1/StackPop, gradients/decode_layer/decoder/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3)]]\n\t [[Node: gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_167 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1529_gradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopgradients/decode_layer/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/TensorArrayReadV3_grad/TensorArrayGrad/TensorArrayGradV3/_59)]]\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 15\n",
    "restore = True\n",
    "lr = 1\n",
    "for i in range(i_save,n_epoch):\n",
    "    \n",
    "    i_save = i\n",
    "    worksum = int(len(train_y)/batch_size)\n",
    "    pb = ProgressBar(worksum=worksum)\n",
    "    pb.startjob()\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    for j in range(worksum):\n",
    "        if restore == True and j < j_save:\n",
    "            pb.finishsum += 1\n",
    "            continue\n",
    "        restore = False\n",
    "        \n",
    "        j_save = j\n",
    "        batch_x,batch_y = train_set.next_batch(batch_size)\n",
    "        lx = [seq_max_len] * batch_size\n",
    "        ly = [seq_max_len] * batch_size\n",
    "        bx = [np.sum(m > 0) for m in batch_x]\n",
    "        by = [np.sum(m > 0) for m in batch_y]\n",
    "        by =[m + 2  if m < seq_max_len - 1 else m for m in by ]\n",
    "        _, loss = session.run([optimizer,train_loss],feed_dict={x:batch_x,y:batch_y,x_len:lx,y_len:ly,learning_rate:lr,y_in:\n",
    "                                                                np.concatenate((\n",
    "                                                                np.ones((batch_y.shape[0],1),dtype=np.int) * ch2ind['<go>'],batch_y[:,:-1]) ,axis=1)\n",
    "                                                                ,y_real_len:by,\n",
    "                                                                x_real_len:bx\n",
    "                                                               })\n",
    "        train_loss_list.append(loss)\n",
    "        #tmp_train_acc = cal_acc(tran,batch_y)\n",
    "        #train_acc_list.append(tmp_train_acc)\n",
    "        pb.info = \"iter {} loss:{} lr:{}\".format(i + 1,loss,lr)\n",
    "        val_step = int(worksum / 4)\n",
    "        if j % val_step == 0 and j != 0:\n",
    "            test_loss,test_acc,bleu_score,predict_list,target_list,source_list = calc_test_loss()\n",
    "            _,train_acc,train_bleu_score,train_predict_list,train_target_list,train_source_list = calc_test_loss(Dataset(train_x[::100],train_y[::100]),display=False)\n",
    "            predict_texts = get_all_text(predict_list)\n",
    "            target_texts = get_all_text(target_list)\n",
    "            source_texts = get_all_en_text(source_list)\n",
    "            \n",
    "            train_predict_texts = get_all_text(train_predict_list)\n",
    "            train_target_texts = get_all_text(train_target_list)\n",
    "            train_source_texts = get_all_en_text(train_source_list)\n",
    "            \n",
    "            with open('eval/{}/{}_{}_predict'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in predict_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "            with open('eval/{}/{}_{}_target'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in target_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "            with open('eval/{}/{}_{}_source'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in source_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "                    \n",
    "            with open('eval/{}/{}_{}_predict_train'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in train_predict_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "            with open('eval/{}/{}_{}_target_train'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in train_target_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "            with open('eval/{}/{}_{}_source_train'.format(model_path,i + 1,j),'w',encoding='utf-8') as whdl:\n",
    "                for line in train_source_texts:\n",
    "                    whdl.write(\"{}\\n\".format(line))\n",
    "            print(\"\\niter {} step {} train loss {} train acc {} test loss {} test acc {} bleu {} lr {}\\n\".format(i+1,j,np.average(train_loss_list[-val_step:]),train_acc,test_loss,test_acc,bleu_score,lr))\n",
    "            try:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.save(session,'middleresult/{}/result_{}_{}'.format(model_path,i + 1,j))\n",
    "            except:\n",
    "                print('save fail')\n",
    "        lr_step = int(worksum / 2) - 1\n",
    "        if j % lr_step == 0 and j != 0:\n",
    "            if (i + 1) >= 7:\n",
    "                lr = lr / 2\n",
    "        pb.complete(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x228b0a0bf60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ind2en.get(i,'') for i in test_x[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent = 'you are too stupid to know that you are an idiot .'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'are',\n",
       " 'too',\n",
       " 'stupid',\n",
       " 'to',\n",
       " 'know',\n",
       " 'that',\n",
       " 'you',\n",
       " 'are',\n",
       " 'an',\n",
       " 'idiot',\n",
       " '.']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = [en2ind.get(i) for i in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = tf.contrib.keras.preprocessing.sequence.pad_sequences([sents],seq_max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  13,   31,  198, 3197,    7,   83,   17,   13,   31,   35, 7122,\n",
       "           3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13,  31, 198, ...,   0,   0,   0],\n",
       "       [ 13,  31, 198, ...,   0,   0,   0],\n",
       "       [ 13,  31, 198, ...,   0,   0,   0],\n",
       "       ..., \n",
       "       [ 13,  31, 198, ...,   0,   0,   0],\n",
       "       [ 13,  31, 198, ...,   0,   0,   0],\n",
       "       [ 13,  31, 198, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(sents,35,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sents[0] > 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tran = session.run([translations],feed_dict={x:np.repeat(sents,64,axis=0),x_len:[35] * 64, x_real_len:[sum(sents[0] > 0) + 1] * 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你太傻了，知道你是个白痴', 34),\n",
       " ('你太傻了，不知道你是个白痴', 8),\n",
       " ('你太傻了，你就知道你是个白痴', 6),\n",
       " ('你太愚蠢了，知道你是个白痴', 2),\n",
       " ('你太傻了，知道你是白痴', 2)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(''.join([ind2ch.get(i,'') for i in j]) for j in tran[0]).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50002, 8824)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ind['<go>'],ch2ind['<go>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# release the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file release already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('release/align_and_translate_char_50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'release/align_and_translate_char_50000/align_and_translate_model'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(session,'release/align_and_translate_char_50000/align_and_translate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('release/align_and_translate_char_50000/dic.pkl','wb') as whdl:\n",
    "    pickle.dump(\n",
    "        ( \n",
    "            ind2ch,\n",
    "            ch2ind,\n",
    "            ind2en,\n",
    "            en2ind,\n",
    "        ),whdl,protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
